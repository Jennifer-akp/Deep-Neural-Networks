{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# define the neural networks\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Formatting raw data to Deep Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize the data before combining or stacking the attributes. (Note that all the reported attributes are measured in the same units (gravity) and in similar order of magnitude so standardizing may have marginal effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the train data set\n",
    "TrainData= loadmat('./Desktop/DataSet/rawSensorData_train.mat')\n",
    "##display (TrainData)\n",
    "\n",
    "##rename all features (6 features in total)\n",
    "gyro_x_train = TrainData['body_gyro_x_train']\n",
    "gyro_y_train = TrainData['body_gyro_y_train']\n",
    "gyro_z_train = TrainData['body_gyro_z_train']\n",
    "\n",
    "acc_x_train = TrainData ['total_acc_x_train']\n",
    "acc_y_train = TrainData ['total_acc_y_train']\n",
    "acc_z_train = TrainData ['total_acc_z_train']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load test data set\n",
    "TestData = loadmat('./Desktop/DataSet/rawSensorData_test.mat')\n",
    "##display(TestData)\n",
    "\n",
    "##rename all features (6 features in total)\n",
    "gyro_x_test = TestData['body_gyro_x_test']\n",
    "gyro_y_test = TestData['body_gyro_y_test']\n",
    "gyro_z_test = TestData['body_gyro_z_test']\n",
    "\n",
    "acc_x_test = TestData ['total_acc_x_test']\n",
    "acc_y_test = TestData ['total_acc_y_test']\n",
    "acc_z_test = TestData ['total_acc_z_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "##standardizing the train and test data set\n",
    "sc = ss()\n",
    "\n",
    "##for gyroscope\n",
    "gyro_x_train_1 = sc.fit_transform(gyro_x_train)\n",
    "gyro_x_test_1 = sc.transform(gyro_x_test)\n",
    "\n",
    "gyro_y_train_1 = sc.fit_transform(gyro_y_train)\n",
    "gyro_y_test_1 = sc.transform(gyro_y_test)\n",
    "\n",
    "gyro_z_train_1 = sc.fit_transform(gyro_z_train)\n",
    "gyro_z_test_1 = sc.transform(gyro_z_test)\n",
    "\n",
    "##for accelerometer\n",
    "acc_x_train_1 = sc.fit_transform(acc_x_train)\n",
    "acc_x_test_1 = sc.transform(acc_x_test)\n",
    "\n",
    "acc_y_train_1 = sc.fit_transform(acc_y_train)\n",
    "acc_y_test_1 = sc.transform(acc_y_test)\n",
    "\n",
    "acc_z_train_1 = sc.fit_transform(acc_z_train)\n",
    "acc_z_test_1 = sc.transform(acc_z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider each attribute in the training [7352,128] will be stacked in the “axis=2” dimension (counting from 0), often called an input channel. We use np.stack so we obtain [7352,128,6] array, corresponding to [axis=0,1,2] as [num_samples, num_timesteps, num_attributes]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 6)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData1 = np.stack([acc_x_train_1,\n",
    "                      acc_y_train_1,\n",
    "                      acc_z_train_1,\n",
    "                      gyro_x_train_1,\n",
    "                      gyro_y_train_1,\n",
    "                      gyro_z_train_1], axis = 2)\n",
    "##display (TrainData1[0:5])\n",
    "TrainData1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Repeat for test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 128, 6)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData1 = np.stack([acc_x_test_1,\n",
    "                      acc_y_test_1,\n",
    "                      acc_z_test_1,\n",
    "                      gyro_x_test_1,\n",
    "                      gyro_y_test_1,\n",
    "                      gyro_z_test_1], axis = 2)\n",
    "##display (TestData1[0:5])\n",
    "TestData1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert labels (1 to 5) to 0 to 4, and perform one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label shape (7352, 1)\n",
      "test label shape (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "#obtain the labels. \n",
    "labels = loadmat('./Desktop/DataSet/labels.mat')\n",
    "train_labels = labels['train_labels']\n",
    "test_labels = labels['test_labels']\n",
    "\n",
    "print('train label shape', train_labels.shape)\n",
    "print('test label shape',test_labels.shape)\n",
    "\n",
    "#encode/transform so the class starts at 0 to 4 rather than 1 to 5.\n",
    "dict = {1:0,2:1,3:2,4:3,5:4}\n",
    "train_labels = np.vectorize(dict.get)(train_labels)\n",
    "test_labels = np.vectorize(dict.get)(test_labels)\n",
    "\n",
    "\n",
    "#convert to one-hot\n",
    "train_labels_enc = to_categorical(train_labels)\n",
    "test_labels_enc = to_categorical(test_labels)\n",
    "\n",
    "# display (train_labels_enc [0:5])\n",
    "# display (test_labels_enc [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement the Deep Neural Network Classifier: Note the parameter and layer tuning is usually up to the designer, here is my architecture and tuning which converges. If your computer has “Out of memory” problem, consider reducing the number of neurons, and the batchsize in step h.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#parameters for neural net\n",
    "num_inputs = TrainData1.shape[1] # Total number 0f input variables (per sample)\n",
    "num_channels = TrainData1.shape[2] #number of channels (1)\n",
    "num_labels = train_labels_enc.shape[1] # Total number of output labels - 3.\n",
    "\n",
    "print (num_inputs)\n",
    "print (num_channels)\n",
    "print (num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Use a Conv1D layer with 100 filters, a sliding kernel filter of 10, padding=’causal’, Relu activation, and input shape of [num_timesteps, num_attributes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build CNN MODEL\n",
    "model = Sequential()  \n",
    "model.add(Conv1D(100, 10, padding='causal', activation='relu', input_shape=(num_inputs, num_channels)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Add another Conv1D layer with 150 filters, sliding kernel of 20, padding=’causal’, Relu activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(150, 20, padding='causal', activation='relu', input_shape=(num_inputs, num_channels)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Use the “GlobalAveragePooling1D” to reduce the convolutional output to a 1D vector to use as features to a standard neural network (dense layer and output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GlobalAveragePooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Add a dense layer with 128 neurons, followed by ‘relu” activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Add a dropout layer with dropout probability of 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. In the output layer, specify a N=5 neuron output, with ‘softmax’ activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 128, 100)          6100      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 150)          300150    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 150)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               19328     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 326,223\n",
      "Trainable params: 326,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##num_labels, N = 5 neuron output\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Compile the model, using ‘adam’ optimizer, loss as ‘categorical_crossentropy’, and metrics of [‘accuracy’]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h. Fit (train) the model using the training [7352,128,6] features and train_label for 20 epoch. Specify a batch_size=256. (or smaller batch_size depending on your hardware) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 70s 9ms/step - loss: 0.7275 - accuracy: 0.6999\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.2666 - accuracy: 0.8936\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1656 - accuracy: 0.9368\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.1381 - accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1241 - accuracy: 0.9474\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1161 - accuracy: 0.9491\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1080 - accuracy: 0.9531\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1082 - accuracy: 0.9529\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1016 - accuracy: 0.9559\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0996 - accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0870 - accuracy: 0.9589\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0807 - accuracy: 0.9631\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.0858 - accuracy: 0.9616\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.0783 - accuracy: 0.9656\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.0718 - accuracy: 0.9672\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0700 - accuracy: 0.9683\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0707 - accuracy: 0.9694\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.0674 - accuracy: 0.9694\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.0661 - accuracy: 0.9702\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.0616 - accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(TrainData1, train_labels_enc, batch_size= 256, epochs=20)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Evaluate the results of the model on the [2549,128,6] test feature and test_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.4555106203815857\n",
      "\n",
      "Test accuracy: 91.00780487060547\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(TestData1,test_labels_enc, verbose=2)\n",
    "print('\\nTest loss:', test_loss)  \n",
    "print('\\nTest accuracy:', (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Print the model.summary(). For each layer, using the output shape as a guide, verify the number of parameters (Param #) is correct. \n",
    "<b/>i. Hint 1: In the conv layers, each filter has a certain number of neurons for the convolution weights per [num_attributes], \n",
    "<br/>ii. Hint 2: https://keras.io/layers/pooling/ \n",
    "<br/>iii. Hint 3: Dense layers: output = Wx+b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 128, 100)          6100      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 150)          300150    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 150)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               19328     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 326,223\n",
      "Trainable params: 326,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula is : input channels * weights *filters + biases\n",
      "The formula is :  inputs * outputs (x) + biases(b) \n",
      "\n",
      "\n",
      "For Layer 1: \n",
      "input channels = 6,\n",
      "weights = 10 ,\n",
      "filters = 100 ,\n",
      "biases = 100(1 per filter)\n",
      "Param Number = 6100\n",
      "\n",
      "  \n",
      "For Layer 2: \n",
      "input channels = 100,\n",
      "weights = 20 ,\n",
      "filters = 150 ,\n",
      "biases = 150(1 per filter)\n",
      "Param Number = 300150\n",
      "\n",
      "  \n",
      "For Layer 3: \n",
      "inputs = 20 ,\n",
      "outputs = 128 ,\n",
      "biases = 128 \n",
      "Param Number = 19328\n",
      "\n",
      "  \n",
      "For Layer 4: \n",
      "inputs = 128 ,\n",
      "outputs = 128 ,\n",
      "biases = 128 \n",
      "Param Number = 16512\n",
      "\n",
      "  \n",
      "For Layer 5: \n",
      "inputs = 128 ,\n",
      "outputs = 5 ,\n",
      "biases = 5 \n",
      "Param Number = 645\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print ('The formula is : input channels * weights *filters + biases')\n",
    "print ('The formula is :  inputs * outputs (x) + biases(b) \\n\\n')\n",
    "\n",
    "\n",
    "print('For Layer 1: \\n' \n",
    "      'input channels = 6,\\n'\n",
    "      'weights = 10 ,\\n' \n",
    "      'filters = 100 ,\\n'\n",
    "      'biases = 100(1 per filter)\\n'\n",
    "      'Param Number = %d' % (6*10*100+100))\n",
    "print ('''\n",
    "  ''')\n",
    "\n",
    "\n",
    "print('For Layer 2: \\n' \n",
    "      'input channels = 100,\\n'\n",
    "      'weights = 20 ,\\n' \n",
    "      'filters = 150 ,\\n'\n",
    "      'biases = 150(1 per filter)\\n'\n",
    "      'Param Number = %d' % (100*20*150+150))\n",
    "print ('''\n",
    "  ''')\n",
    "\n",
    "print('For Layer 3: \\n' \n",
    "      'inputs = 20 ,\\n' \n",
    "      'outputs = 128 ,\\n'\n",
    "      'biases = 128 \\n'\n",
    "      'Param Number = %d' % (150*128+128))\n",
    "print ('''\n",
    "  ''')\n",
    "\n",
    "\n",
    "print('For Layer 4: \\n' \n",
    "      'inputs = 128 ,\\n' \n",
    "      'outputs = 128 ,\\n'\n",
    "      'biases = 128 \\n'\n",
    "      'Param Number = %d' % (128*128+128))\n",
    "print ('''\n",
    "  ''')\n",
    "\n",
    "print('For Layer 5: \\n' \n",
    "      'inputs = 128 ,\\n' \n",
    "      'outputs = 5 ,\\n'\n",
    "      'biases = 5 \\n'\n",
    "      'Param Number = %d' % (128*5+5))\n",
    "print ('''\n",
    "  ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Plot the training cross entropy loss, the training accuracy with the number of epoch (full iterations over dataset) in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a41974128>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.title('Model training cross entropy loss & training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='center right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Output the confusion matrix and accuracy for both training and test data with deep neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set for neural network = 0.9789173014145811\n",
      "The confusion matrix for training set for neural network is\n",
      " [[1407    0    0    0    0]\n",
      " [   0 1207    0   79    0]\n",
      " [   0    0 2059    0    0]\n",
      " [   0   74    0 1300    0]\n",
      " [   0    0    2    0 1224]]\n",
      "\n",
      "Accuracy for test set for neural network = 0.9100780454699695\n",
      "The confusion matrix for test set for neural network is\n",
      " [[537   0   0   0   0]\n",
      " [  0 401  25  65   0]\n",
      " [  0   0 869   0  22]\n",
      " [  0  96   3 431   2]\n",
      " [  0   0  52   0 444]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict (TestData1)\n",
    "cm_test = confusion_matrix(test_labels_enc.argmax(axis=1), y_pred_test.argmax(axis=1))\n",
    "\n",
    "y_pred_train = model.predict(TrainData1)\n",
    "cm_train = confusion_matrix(train_labels_enc.argmax(axis=1), y_pred_train.argmax(axis=1))\n",
    "\n",
    "\n",
    "print('Accuracy for training set for neural network = {}'.format((np.trace(cm_train))/len(train_labels_enc)))\n",
    "print('The confusion matrix for training set for neural network is\\n',cm_train)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Accuracy for test set for neural network = {}'.format((np.trace(cm_test))/len(test_labels_enc)))\n",
    "print('The confusion matrix for test set for neural network is\\n', cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Output the softmax probability of the first 5 test samples and compare with true label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Predicted output for first 5 test samples is \n",
      " [3, 3, 3, 3, 3]\n",
      "The Actual output for firsr 5 test samples is \n",
      " [3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict (TestData1 [0:5])\n",
    "\n",
    "\n",
    "print ('The Predicted output for first 5 test samples is \\n' ,[np.argmax(x) for x in predict])\n",
    "print ('The Actual output for firsr 5 test samples is \\n', test_labels[0:5].reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. For the deep neural network, based on confusion matrix and previous analysis, which classes of activities are the most difficult and which ones conversely are easy to “classify”? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Laying       1.00      1.00      1.00       537\n",
      "        Sitting       0.81      0.82      0.81       491\n",
      "Climbing Stairs       0.92      0.98      0.94       891\n",
      "       Standing       0.87      0.81      0.84       532\n",
      "        Walking       0.95      0.90      0.92       496\n",
      "\n",
      "       accuracy                           0.91      2947\n",
      "      macro avg       0.91      0.90      0.90      2947\n",
      "   weighted avg       0.91      0.91      0.91      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = ['Laying', 'Sitting', 'Climbing Stairs', 'Standing', 'Walking']\n",
    "\n",
    "\n",
    "result=metrics.classification_report(test_labels, y_pred_test.argmax(axis = 1), labels=None, target_names= label, \n",
    "                                      sample_weight=None, digits=2, output_dict=False)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest activity to classify is Laying.\n",
    "<br/>Sitting and Standing are the most to difficult to classify.\n",
    "<br/>Climbing stairs and Walking are often confused and are also hard to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. What parameters are modifiable to the analyst in a deep neural network? You may use terminology used in the Keras libraries to guide your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate can be changed, The number of epochs can be increased, number of layers increased, sgd optimizer could be used, regularization can be introduced, differnt activations could have been used also, loss functions, and performance metrics also changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Discuss any advantages or applications of using convolutional layers over choosing hand-crafted statistical features (i.e. mean, standard deviation). *Note that the current dataset, the task (predicting the activity) is already quite separable with the hand-crafted features [Assignment 3 from the 3D plots]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers can be used for image recognition where the features are not easily classifiable. In CNN, the features are learned by the classifier and this comes very handy in image recognition which annot be easily hand crafted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
